version: '3.9'

services:
  vllm-qwen:
    image: vllm/vllm-openai:latest
    container_name: blackroad-vllm-qwen
    restart: unless-stopped
    # Deploy to Jetson Orin Nano (has GPU)
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - MODEL_NAME=Qwen/Qwen2.5-7B-Instruct
      - MAX_MODEL_LEN=4096
      - GPU_MEMORY_UTILIZATION=0.9
      - SERVED_MODEL_NAME=qwen2.5:7b
    ports:
      - "8083:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    command: >
      --model Qwen/Qwen2.5-7B-Instruct
      --max-model-len 4096
      --gpu-memory-utilization 0.9
      --dtype auto
      --api-key ${VLLM_API_KEY:-blackroad-vllm-key-2025}
      --served-model-name qwen2.5:7b
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - blackroad-ai-net

  # Optional: Smaller model for CPU-only Pis
  vllm-phi:
    image: vllm/vllm-openai:latest
    container_name: blackroad-vllm-phi
    restart: unless-stopped
    environment:
      - MODEL_NAME=microsoft/phi-2
      - MAX_MODEL_LEN=2048
      - SERVED_MODEL_NAME=phi-2
    ports:
      - "8084:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    command: >
      --model microsoft/phi-2
      --max-model-len 2048
      --dtype float16
      --api-key ${VLLM_API_KEY:-blackroad-vllm-key-2025}
      --served-model-name phi-2
    networks:
      - blackroad-ai-net
    profiles:
      - cpu-fallback

  # Ollama as alternative/backup
  ollama:
    image: ollama/ollama:latest
    container_name: blackroad-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - blackroad-ai-net
    profiles:
      - backup

networks:
  blackroad-ai-net:
    driver: bridge

volumes:
  ollama_data:
